{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "pytorch-mnist-GAN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpuzAeOwbzsl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "    Navigate to Editâ†’Notebook Settings\n",
        "    select GPU from the Hardware Accelerator drop-down\n",
        "    \n",
        "You can check if the GPU works with nvidia-smi.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNHZIuP6cFMm",
        "colab_type": "code",
        "outputId": "aa5d17b4-026c-4301-f5c8-8382fdccbd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 31 15:30:25 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    58W / 149W |    407MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oRSvaqfUlos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7iO5n_RcgEf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Data Loading\n",
        "We provide the code for data loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo0BDnY3Ulo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 100\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SFLB5Tcw8f",
        "colab_type": "text"
      },
      "source": [
        "Specify the generator and the discriminator to get the following architectures:\n",
        "\n",
        "```\n",
        " Generator(\n",
        "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
        "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
        "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
        "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "Discriminator(\n",
        "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
        "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
        "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
        "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "We recommend the use of leaky-relu for the hidden layers and tanh for the last layer of the generator. We let you chose the appropriate activation for the last layer of the discriminator. We also recommend using dropout(0.3) in the discriminator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNFUY2uGUlo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()       \n",
        "        #...  \n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "        #...\n",
        "        return #...\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        #...\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        #...\n",
        "        return #..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfI_FuVMdtkE",
        "colab_type": "text"
      },
      "source": [
        "## We instantiate the networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS15z0WoUlpB",
        "colab_type": "code",
        "outputId": "a5abaf60-4d63-4dd6-b569-6dcdcd963f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# build network\n",
        "z_dim = 100\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OOhS6dyd7wh",
        "colab_type": "text"
      },
      "source": [
        "You can check if the architectures are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHiGI1x7UlpF",
        "colab_type": "code",
        "outputId": "6e7b999e-139d-4a6a-dde2-ed742ab56596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "G"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyt3-pjEUlpL",
        "colab_type": "code",
        "outputId": "ad076822-2921-4984-9cc2-b05e1813b0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2x6Yh2teKq8",
        "colab_type": "text"
      },
      "source": [
        "## Training configuration\n",
        "Chose the discriminator loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXYMnF-zUlpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss\n",
        "criterion = # ...\n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002 \n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2UGG7tDfe7F",
        "colab_type": "text"
      },
      "source": [
        "Now, let's code the discriminator update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0HfK1ZUlpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(x): # x is a batch composed of images\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # we use 1 for real and 0 for fake\n",
        "    # train discriminator on real\n",
        "    x_real = x.view(-1, mnist_dim)\n",
        "    y_real = # ...\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = # ...\n",
        "    D_real_loss = # ...\n",
        "    \n",
        "\n",
        "    # train discriminator on facke\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake = # ... generate fake images\n",
        "    y_fake = # ... labels\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    \n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FGZbrUwfneF",
        "colab_type": "text"
      },
      "source": [
        "Now, let's code the generator update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hzq2DmsUlpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train():\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = # ...\n",
        "\n",
        "    G_output =  # ... look at the discriminiator function, this is similar\n",
        "    D_output =  # ...\n",
        "    G_loss =  # ...\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDHfabhUf1n_",
        "colab_type": "text"
      },
      "source": [
        "We provide this visualization function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QyTKUZ2V-Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the loss from each batch\n",
        "def plotLoss(epoch):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(dLosses, label='Discriminitive loss')\n",
        "    plt.plot(gLosses, label='Generative loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('gan_loss_epoch_%d.png' % epoch)\n",
        "\n",
        "# Create a wall of generated MNIST images\n",
        "def plotGeneratedImages(generatedImages,dim=(10, 10), figsize=(10, 10)):\n",
        "    generatedImages=generatedImages.cpu().numpy()\n",
        "    print(generatedImages.shape)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generatedImages.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(np.squeeze(generatedImages[i]), interpolation='nearest', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)\n",
        "    IPython.display.display(IPython.display.Image(data=('gan_generated_image_epoch_%d.png' % epoch)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsw8ksyOgTM4",
        "colab_type": "text"
      },
      "source": [
        "Finally, this is the main loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "14zYPe0LUlpb",
        "colab_type": "code",
        "outputId": "13e29f90-bbe7-4729-af70-e5a47f0dd789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "n_epoch = 20\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        loss_D= # ...\n",
        "        D_losses.append(loss_D)\n",
        "        loss_G= # ....\n",
        "        G_losses.append(loss_G)\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "        generated = G(test_z)\n",
        "        plotGeneratedImages(generated.view(generated.size(0), 1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-32d30c2ca5a1>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    loss_D= # ...\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9en3b1I2Z-KK",
        "colab_type": "text"
      },
      "source": [
        "DCGAN\n",
        "\n",
        "Save a copy of your colab. Now, we will implement a version of GAN that uses convolutions: DCGAN. You can find the paper [here](https://arxiv.org/abs/1511.06434). The main idea of DCGAN is to use convolutions in the generator and discriminator in order to get images that are more spacially consistent. Replace your naive generator and decoder by the DCGAN architectures. This is slower to train but by looking at the images after one epoch, you can already draw an interesting conclusion. The architecture is not clearly specified for mnist. You can use the following generator (use leakyRelu):\n",
        "\n",
        "\n",
        "*   Dense(128x7x7) \n",
        "*   UpSampling2D\n",
        "*   Conv2D(64, kernel_size=(5, 5)\n",
        "*   UpSampling2D\n",
        "*   Conv2D(1, kernel_size=(5, 5) \n",
        "\n",
        "Use a tanh activation at the end.\n",
        "\n",
        "For the discriminator:\n",
        "\n",
        "\n",
        "* Conv2D(64, kernel_size=(5, 5), strides=(2, 2)\n",
        "* Conv2D(128, kernel_size=(5, 5), strides=(2, 2)\n",
        "* Dense(1, activation='sigmoid'))\n"
      ]
    }
  ]
}